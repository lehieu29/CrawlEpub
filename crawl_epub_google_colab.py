!pip install requests beautifulsoup4 ebooklib tqdm lxml

import os
import re
import time
import random
import requests
import traceback
import json
import threading
import queue
from bs4 import BeautifulSoup
from google.colab import drive
from google.colab import userdata
from ebooklib import epub
from IPython.display import display, HTML
from tqdm.notebook import tqdm
import uuid
from urllib.parse import urlparse, unquote

# Mount Google Drive
drive.mount('/content/drive')

# Create a queue and event for checkpoint saving
save_queue = queue.Queue()
exit_event = threading.Event()

# T·∫°o queue cho vi·ªác l∆∞u file debug
debug_save_queue = queue.Queue()
debug_save_event = threading.Event()

# L∆∞u checkpoint m·ªói 50 ch∆∞∆°ng
checkpoint_interval = 50

# T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a t·ªìn t·∫°i
temp_folder = '/content/drive/My Drive/Book/Novel/Temp'
main_folder = '/content/drive/My Drive/Book/Novel'
os.makedirs(temp_folder, exist_ok=True)
os.makedirs(main_folder, exist_ok=True)

# H√†m t·∫°m d·ª´ng c√≥ th√¥ng b√°o
def delay(second):
    """T·∫°m d·ª´ng th·ª±c thi v·ªõi th√¥ng b√°o"""
    print(f"‚è≥ Delay {second:.2f}s...")
    time.sleep(second)

# H√†m sinh ng·∫´u nhi√™n user-agent
def generate_user_agent():
    try:
        user_agents = [
            # Chrome
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.63 Safari/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.81 Safari/537.36",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.114 Safari/537.36",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.159 Safari/537.36",
            # Firefox
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:89.0) Gecko/20100101 Firefox/89.0",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:90.0) Gecko/20100101 Firefox/90.0",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:91.0) Gecko/20100101 Firefox/91.0",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:89.0) Gecko/20100101 Firefox/89.0",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:90.0) Gecko/20100101 Firefox/90.0",
            # Safari
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.1 Safari/605.1.15",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.0 Safari/605.1.15",
            # Edge
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36 Edg/91.0.864.59",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36 Edg/92.0.902.62",
            # Opera
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36 OPR/77.0.4054.254",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36 OPR/78.0.4093.112",
            # Mobile
            "Mozilla/5.0 (iPhone; CPU iPhone OS 14_6 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.1 Mobile/15E148 Safari/604.1",
            "Mozilla/5.0 (iPhone; CPU iPhone OS 15_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.0 Mobile/15E148 Safari/604.1",
            "Mozilla/5.0 (Linux; Android 11; SM-G991B) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.120 Mobile Safari/537.36",
            "Mozilla/5.0 (Linux; Android 12; Pixel 5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.159 Mobile Safari/537.36"
        ]
        return random.choice(user_agents)
    except Exception as e:
        print("L·ªói khi sinh user-agent: " + str(e))
        traceback.print_exc()
        # Return a default user agent in case of error
        return "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"

# Thread cho vi·ªác l∆∞u file debug
def debug_save_thread():
    while not debug_save_event.is_set():
        try:
            # Try to get a save task from the queue with timeout
            save_task = debug_save_queue.get(timeout=1.0)
            if save_task:
                try:
                    novel_title, chapter_info, html_content, folder_path = save_task

                    # ƒê·∫£m b·∫£o th∆∞ m·ª•c t·ªìn t·∫°i
                    os.makedirs(folder_path, exist_ok=True)

                    # T·∫°o t√™n file an to√†n - x·ª≠ l√Ω tr∆∞·ªùng h·ª£p kh√¥ng c√≥ chapter_info
                    if not chapter_info or not isinstance(chapter_info, dict):
                        # N·∫øu kh√¥ng c√≥ chapter_info, t·∫°o t√™n file d·ª±a tr√™n timestamp
                        timestamp = int(time.time())
                        file_name = f"debug_{timestamp}.html"
                    else:
                        # L·∫•y th√¥ng tin ch∆∞∆°ng n·∫øu c√≥
                        chapter_num = chapter_info.get('index', '0')
                        chapter_title = chapter_info.get('name', 'unknown')

                        # T·∫°o t√™n file an to√†n
                        safe_title = re.sub(r'[\\/*?:"<>|]', "_", str(chapter_title))
                        file_name = f"{chapter_num}_{safe_title}.html"

                    # ƒê∆∞·ªùng d·∫´n ƒë·∫ßy ƒë·ªß
                    file_path = os.path.join(folder_path, file_name)

                    # L∆∞u n·ªôi dung
                    with open(file_path, 'w', encoding='utf-8') as f:
                        f.write(html_content)

                    print(f"üîç ƒê√£ l∆∞u file debug: {file_path}")
                except Exception as e:
                    print(f"‚ö†Ô∏è L·ªói khi l∆∞u file debug: {e}")
                    traceback.print_exc()

                    # Th·ª≠ l∆∞u v·ªõi t√™n file ƒë∆°n gi·∫£n nh·∫•t trong tr∆∞·ªùng h·ª£p l·ªói
                    try:
                        timestamp = int(time.time())
                        simple_path = os.path.join(temp_folder, f"debug_error_{timestamp}.html")
                        with open(simple_path, 'w', encoding='utf-8') as f:
                            f.write(html_content)
                        print(f"üîç ƒê√£ l∆∞u file debug d·ª± ph√≤ng: {simple_path}")
                    except:
                        print("‚ùå Kh√¥ng th·ªÉ l∆∞u file debug d√π ƒë√£ th·ª≠ ph∆∞∆°ng √°n d·ª± ph√≤ng")

                debug_save_queue.task_done()
        except queue.Empty:
            # No save task in queue, continue checking
            pass
        except Exception as e:
            print(f"‚ùå L·ªói trong lu·ªìng l∆∞u debug: {e}")
            traceback.print_exc()

# H√†m th√™m t√°c v·ª• l∆∞u file debug v√†o queue
def queue_debug_save(novel_title, chapter_info, html_content):
    try:
        # X·ª≠ l√Ω tr∆∞·ªùng h·ª£p novel_title r·ªóng ho·∫∑c None
        if not novel_title:
            novel_title = "Unknown_Novel"

        # T·∫°o t√™n th∆∞ m·ª•c an to√†n
        safe_title = re.sub(r'[\\/*?:"<>|]', "_", str(novel_title))
        folder_path = os.path.join(temp_folder, safe_title)

        # Th√™m v√†o queue
        debug_save_queue.put((novel_title, chapter_info, html_content, folder_path))
    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói khi th√™m nhi·ªám v·ª• l∆∞u debug: {e}")
        traceback.print_exc()

        # Th·ª≠ l∆∞u tr·ª±c ti·∫øp m√† kh√¥ng qua queue trong tr∆∞·ªùng h·ª£p l·ªói nghi√™m tr·ªçng
        try:
            timestamp = int(time.time())
            emergency_path = os.path.join(temp_folder, f"emergency_debug_{timestamp}.html")
            with open(emergency_path, 'w', encoding='utf-8') as f:
                f.write(html_content)
            print(f"üîç ƒê√£ l∆∞u file debug kh·∫©n c·∫•p: {emergency_path}")
        except:
            print("‚ùå Kh√¥ng th·ªÉ l∆∞u file debug trong tr∆∞·ªùng h·ª£p kh·∫©n c·∫•p")

# Background thread function for saving checkpoints
def checkpoint_saver_thread():
    while not exit_event.is_set():
        try:
            # Try to get a save task from the queue with timeout
            save_task = save_queue.get(timeout=1.0)
            if save_task:
                book, intro, chapters, output_path = save_task
                try:
                    save_epub(book, intro, chapters, output_path, True)
                    print(f"\n\n‚ú®‚ú®‚ú® ƒê√£ l∆∞u t·∫°m checkpoint sau {len(chapters)} ch∆∞∆°ng... ‚ú®‚ú®‚ú®\n\n")
                except Exception as e:
                    print(f"‚ö†Ô∏è L·ªói khi l∆∞u checkpoint: {e}")
                save_queue.task_done()
        except queue.Empty:
            # No save task in queue, continue checking
            pass
        except Exception as e:
            print(f"‚ùå L·ªói trong lu·ªìng l∆∞u ƒëi·ªÉm ki·ªÉm tra: {e}")
            traceback.print_exc()

# H√†m x√≥a file t·∫°m sau khi l∆∞u th√†nh c√¥ng
def delete_temp_file(temp_path):
    """X√≥a file truy·ªán t·∫°m th·ªùi sau khi ƒë√£ l∆∞u th√†nh c√¥ng v√†o th∆∞ m·ª•c ch√≠nh"""
    try:
        if os.path.exists(temp_path):
            os.remove(temp_path)
            print(f"üßπ ƒê√£ x√≥a file t·∫°m: {temp_path}")
            return True
        else:
            print(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file t·∫°m: {temp_path}")
            return False
    except Exception as e:
        print(f"‚ùå L·ªói khi x√≥a file t·∫°m: {e}")
        traceback.print_exc()
        return False

# H√†m l·∫•y cookie t·ª´ userdata c·ªßa Google Colab
def get_cookie():
    try:
        # Ki·ªÉm tra xem ƒë√£ c√≥ cookie trong userdata ch∆∞a
        try:
            cookie = userdata.get('cookie')
            if cookie:
                print("üîç ƒê√£ t√¨m th·∫•y cookie trong userdata")
                return cookie
        except:
            print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y cookie trong userdata")

        # N·∫øu ch∆∞a c√≥, y√™u c·∫ßu ng∆∞·ªùi d√πng nh·∫≠p cookie
        cookie = input("üîë Nh·∫≠p cookie accessToken: ").strip()

        # L∆∞u cookie v√†o userdata cho l·∫ßn sau
        try:
            userdata.set('cookie', cookie)
            print("ƒê√£ l∆∞u cookie v√†o userdata")
        except Exception as e:
            print("‚ùå Kh√¥ng th·ªÉ l∆∞u cookie v√†o userdata: " + str(e))
            traceback.print_exc()

        return cookie
    except Exception as e:
        print("‚ùå L·ªói khi l·∫•y cookie: " + str(e))
        traceback.print_exc()
        return input("Nh·∫≠p cookie accessToken: ")

# L·∫•y cookie
cookie = get_cookie()

# H√†m request trang web v·ªõi headers ƒë√£ cung c·∫•p
def make_request(url, is_api=False, is_mtc=True):
    try:
        headers = {
            'user-agent': generate_user_agent(),
            'referer': 'https://metruyencv.com/' if is_mtc else 'https://tangthuvien.net/'
        }

        # Th√™m cookie n·∫øu l√† metruyenchu
        if is_mtc:
            headers['cookie'] = 'accessToken=' + cookie

        # Th√™m headers ph√π h·ª£p d·ª±a v√†o lo·∫°i request
        if is_api and is_mtc:
            headers['authorization'] = f'Bearer {cookie}'
            headers['accept'] = 'application/json, text/plain, */*'

        # Th·ª≠ l·∫°i t·ªëi ƒëa 3 l·∫ßn n·∫øu b·ªã l·ªói
        max_retries = 3
        for attempt in range(max_retries):
            try:
                response = requests.get(url, headers=headers)
                response.raise_for_status()
                # Tr·∫£ v·ªÅ JSON n·∫øu l√† API request, ng∆∞·ª£c l·∫°i tr·∫£ v·ªÅ text
                if is_api and is_mtc:
                    return response.json()
                else:
                    return response.text
            except Exception as e:
                print("‚ùå L·ªói khi t·∫£i trang " + url + ", l·∫ßn th·ª≠ " + str(attempt+1) + "/" + str(max_retries) + ": " + str(e))
                traceback.print_exc()
                if attempt < max_retries - 1:
                    delay_time = random.uniform(1, 2)
                    delay(delay_time)  # Ch·ªù 1-2 gi√¢y tr∆∞·ªõc khi th·ª≠ l·∫°i
                else:
                    raise Exception("ƒê√£ th·ª≠ " + str(max_retries) + " l·∫ßn nh∆∞ng kh√¥ng th√†nh c√¥ng: " + str(e))
    except Exception as e:
        print("‚ùå L·ªói kh√¥ng x·ª≠ l√Ω ƒë∆∞·ª£c khi t·∫£i trang " + url + ": " + str(e))
        traceback.print_exc()
        raise

# H√†m x√°c ƒë·ªãnh lo·∫°i trang web t·ª´ URL
def detect_site_type(url):
    if "metruyencv.com" in url.lower():
        return "metruyenchu"
    elif "tangthuvien.net" in url.lower():
        return "tangthuvien"
    else:
        raise ValueError("URL kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£. Hi·ªán t·∫°i ch·ªâ h·ªó tr·ª£ metruyencv.com v√† tangthuvien.net")

# H√†m l·∫•y th√¥ng tin truy·ªán t·ª´ Metruyenchu
def get_mtc_novel_info(url):
    try:
        html = make_request(url, is_mtc=True)
        soup = BeautifulSoup(html, 'html.parser')

        # L·∫•y ti√™u ƒë·ªÅ truy·ªán
        title_elem = soup.select_one('h1 a')
        title = title_elem.text.strip() if title_elem else "Kh√¥ng x√°c ƒë·ªãnh"
        print("üìå Ti√™u ƒë·ªÅ truy·ªán: " + title)

        # L·∫•y t√™n t√°c gi·∫£
        author_elem = soup.select_one('h1 ~ div')
        author = author_elem.text.strip() if author_elem else "Kh√¥ng x√°c ƒë·ªãnh"
        print("üë§ T√°c gi·∫£: " + author)

        # L·∫•y link ·∫£nh b√¨a
        cover_elem = soup.select_one('img.h-60')
        cover_url = cover_elem['src'] if cover_elem and 'src' in cover_elem.attrs else None
        print("üñºÔ∏è ·∫¢nh b√¨a: " + ("C√≥" if cover_url else "Kh√¥ng c√≥"))

        # L·∫•y n·ªôi dung gi·ªõi thi·ªáu
        synopsis_elem = soup.select_one('#synopsis .text-base')
        synopsis = synopsis_elem.get_text('\n', strip=True) if synopsis_elem else ""
        print("üìù Gi·ªõi thi·ªáu: " + ("C√≥" if synopsis else "Kh√¥ng c√≥"))

        # L·∫•y book_id t·ª´ n√∫t "ƒê·ªçc t·ª´ ƒë·∫ßu"
        read_button = soup.select_one('div button[title="ƒê·ªçc t·ª´ ƒë·∫ßu"]')
        book_id = None

        if read_button and read_button.parent:
            data_x_data = read_button.parent.get('data-x-data', '')
            book_id_match = re.search(r'readings\((\d+)\)', data_x_data)
            if book_id_match:
                book_id = book_id_match.group(1)
                print(f"üìò Book ID: {book_id}")
            else:
                print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y book_id trong n√∫t ƒë·ªçc t·ª´ ƒë·∫ßu")
        else:
            print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y n√∫t ƒë·ªçc t·ª´ ƒë·∫ßu")

        # L·∫•y danh s√°ch ch∆∞∆°ng t·ª´ API n·∫øu c√≥ book_id
        chapters_list = []
        if book_id:
            api_url = f"https://backend.metruyencv.com/api/chapters?filter[book_id]={book_id}"
            try:
                api_data = make_request(api_url, is_api=True, is_mtc=True)
                if 'data' in api_data and isinstance(api_data['data'], list):
                    chapters_list = api_data['data']
                    print(f"üìö ƒê√£ l·∫•y th√¥ng tin {len(chapters_list)} ch∆∞∆°ng t·ª´ API")
            except Exception as e:
                print(f"‚ùå L·ªói khi l·∫•y danh s√°ch ch∆∞∆°ng t·ª´ API: {e}")
                traceback.print_exc()

        return {
            'title': title,
            'author': author,
            'cover_url': cover_url,
            'synopsis': synopsis,
            'book_id': book_id,
            'chapters_list': chapters_list,
            'site_type': 'metruyenchu'
        }
    except Exception as e:
        print("‚ùå L·ªói khi l·∫•y th√¥ng tin truy·ªán: " + str(e))
        traceback.print_exc()
        raise

# H√†m l·∫•y th√¥ng tin truy·ªán t·ª´ Tangthuvien
def get_ttv_novel_info(url):
    try:
        html = make_request(url, is_mtc=False)
        soup = BeautifulSoup(html, 'html.parser')

        # L·∫•y ti√™u ƒë·ªÅ truy·ªán
        title_elem = soup.select_one('h1')
        title = title_elem.text.strip() if title_elem else "Kh√¥ng x√°c ƒë·ªãnh"
        print("üìå Ti√™u ƒë·ªÅ truy·ªán: " + title)

        # T√°c gi·∫£ m·∫∑c ƒë·ªãnh
        author = "Kh√¥ng x√°c ƒë·ªãnh"
        # print("üë§ T√°c gi·∫£: " + author)

        # L·∫•y link ·∫£nh b√¨a
        cover_elem = soup.select_one('.book-img img')
        cover_url = cover_elem['src'] if cover_elem and 'src' in cover_elem.attrs else None
        print("üñºÔ∏è ·∫¢nh b√¨a: " + ("C√≥" if cover_url else "Kh√¥ng c√≥"))

        # L·∫•y n·ªôi dung gi·ªõi thi·ªáu
        synopsis_elem = soup.select_one('.book-intro')
        synopsis = synopsis_elem.get_text('\n', strip=True) if synopsis_elem else ""
        print("üìù Gi·ªõi thi·ªáu: " + ("C√≥" if synopsis else "Kh√¥ng c√≥"))

        # L·∫•y book_id
        book_id_elem = soup.select_one('#story_id_hidden')
        book_id = book_id_elem['value'] if book_id_elem else None
        print(f"üìò Book ID: {book_id or 'Kh√¥ng t√¨m th·∫•y'}")

        if not book_id:
            # Kh√¥ng t√¨m th·∫•y book_id th√¨ l∆∞u file ƒë·ªÉ DEBUG
            queue_debug_save(url, null, html)

        # L·∫•y t·ªïng s·ªë ch∆∞∆°ng
        total_chapters = 0
        catalog_elem = soup.select_one('#j-bookCatalogPage')
        if catalog_elem:
            chapter_count_match = re.search(r'Danh s√°ch ch∆∞∆°ng \((\d+) ch∆∞∆°ng\)', catalog_elem.text)
            if chapter_count_match:
                total_chapters = int(chapter_count_match.group(1))
                print(f"üìö T·ªïng s·ªë ch∆∞∆°ng: {total_chapters}")

        # L·∫•y danh s√°ch ch∆∞∆°ng
        chapters_list = []
        if book_id and total_chapters > 0:
            chapters_url = f"https://tangthuvien.net/doc-truyen/page/{book_id}?page=0&limit={total_chapters}&web=1"
            try:
                chapters_html = make_request(chapters_url, is_mtc=False)
                chapters_soup = BeautifulSoup(chapters_html, 'html.parser')
                chapter_links = chapters_soup.select('ul.cf > li > a')

                for i, link in enumerate(chapter_links, 1):
                    chapter_url = link.get('href')
                    chapter_title = link.get('title') or f"Ch∆∞∆°ng {i}"

                    chapters_list.append({
                        'index': i,
                        'name': chapter_title,
                        'url': chapter_url
                    })

                print(f"üìö ƒê√£ l·∫•y th√¥ng tin {len(chapters_list)} ch∆∞∆°ng")
            except Exception as e:
                print(f"‚ùå L·ªói khi l·∫•y danh s√°ch ch∆∞∆°ng t·ª´ Tangthuvien: {e}")
                traceback.print_exc()

        return {
            'title': title,
            'author': author,
            'cover_url': cover_url,
            'synopsis': synopsis,
            'book_id': book_id,
            'chapters_list': chapters_list,
            'site_type': 'tangthuvien'
        }
    except Exception as e:
        print("‚ùå L·ªói khi l·∫•y th√¥ng tin truy·ªán t·ª´ Tangthuvien: " + str(e))
        traceback.print_exc()
        raise

# H√†m l·∫•y th√¥ng tin truy·ªán (t·ª± nh·∫≠n bi·∫øt trang)
def get_novel_info(url):
    site_type = detect_site_type(url)
    if site_type == "metruyenchu":
        return get_mtc_novel_info(url)
    elif site_type == "tangthuvien":
        return get_ttv_novel_info(url)
    else:
        raise ValueError("Kh√¥ng h·ªó tr·ª£ lo·∫°i trang web n√†y")

# H√†m tr√≠ch xu·∫•t ti√™u ƒë·ªÅ ch∆∞∆°ng t·ª´ n·ªôi dung
def extract_chapter_title(chapter_number, content=None, default_title=None):
    """Tr√≠ch xu·∫•t ho·∫∑c t·∫°o ti√™u ƒë·ªÅ ch∆∞∆°ng ph√π h·ª£p"""
    # N·∫øu ƒë√£ c√≥ ti√™u ƒë·ªÅ t·ªët, s·ª≠ d·ª•ng n√≥
    if default_title and default_title != f"Ch∆∞∆°ng {chapter_number}" and default_title != "":
        return default_title

    # C·ªë g·∫Øng tr√≠ch xu·∫•t ti√™u ƒë·ªÅ t·ª´ n·ªôi dung n·∫øu c√≥
    if content:
        try:
            title_pattern = re.compile(r"Ch∆∞∆°ng\s+\d+\s*[:\-]\s*(.*?)[\n\r]", re.IGNORECASE)
            match = title_pattern.search(content)
            if match:
                return f"Ch∆∞∆°ng {chapter_number}: {match.group(1).strip()}"
        except Exception as e:
            print(f"‚ö†Ô∏è L·ªói khi tr√≠ch xu·∫•t ti√™u ƒë·ªÅ: {e}")

    # Ti√™u ƒë·ªÅ m·∫∑c ƒë·ªãnh ch·ªâ v·ªõi s·ªë ch∆∞∆°ng
    return f"Ch∆∞∆°ng {chapter_number}"

# H√†m tr√≠ch xu·∫•t ti√™u ƒë·ªÅ t·ª´ n·ªôi dung HTML
def extract_title_from_html(html_content):
    """Tr√≠ch xu·∫•t ti√™u ƒë·ªÅ t·ª´ n·ªôi dung HTML, th∆∞·ªùng t·ª´ th·∫ª h2"""
    try:
        if not html_content:
            return None

        soup = BeautifulSoup(html_content, 'html.parser')

        # T√¨m th·∫ª h2 ƒë·∫ßu ti√™n (th∆∞·ªùng l√† ti√™u ƒë·ªÅ ch∆∞∆°ng)
        # h2 = soup.find('h2')
        #if h2 and h2.text.strip():
        #    return h2.text.strip()

        # Ho·∫∑c t√¨m trong title
        title_tag = soup.find('title')
        if title_tag and title_tag.text.strip():
            return title_tag.text.strip()

        return None
    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói khi tr√≠ch xu·∫•t ti√™u ƒë·ªÅ t·ª´ HTML: {e}")
        return None

# H√†m chu·∫©n h√≥a v√† t·ªëi ∆∞u HTML cho e-reader
def optimize_html_for_ereader(html_content):
    """T·ªëi ∆∞u h√≥a n·ªôi dung HTML cho thi·∫øt b·ªã ƒë·ªçc s√°ch ƒëi·ªán t·ª≠"""
    try:
        if not html_content:
            return html_content

        # Parse HTML
        soup = BeautifulSoup(html_content, 'html.parser')

        # 1. Lo·∫°i b·ªè c√°c thu·ªôc t√≠nh kh√¥ng c·∫ßn thi·∫øt
        for tag in soup.find_all(True):
            allowed_attrs = ['id', 'class', 'href', 'src', 'alt']
            attrs = dict(tag.attrs)
            for attr in attrs:
                if attr not in allowed_attrs:
                    del tag[attr]

        # 2. T√°ch c√°c ƒëo·∫°n vƒÉn d√†i
        for p in soup.find_all('p'):
            if len(p.get_text()) > 1000:  # N·∫øu ƒëo·∫°n vƒÉn qu√° d√†i
                text = p.get_text()
                p.clear()

                # Chia nh·ªè ƒëo·∫°n vƒÉn
                sentences = re.split(r'(?<=[.!?])\s+', text)
                current_p = p

                for i, sentence in enumerate(sentences):
                    if i > 0 and i % 3 == 0:  # M·ªói 3 c√¢u t·∫°o ƒëo·∫°n m·ªõi
                        new_p = soup.new_tag('p')
                        current_p.insert_after(new_p)
                        current_p = new_p

                    if current_p.string:
                        current_p.string = current_p.string + " " + sentence
                    else:
                        current_p.string = sentence

        # 3. Th√™m ng·∫Øt trang sau m·ªói ~10 ƒëo·∫°n vƒÉn
        # paragraphs = soup.find_all('p')
        # for i, p in enumerate(paragraphs):
        #    if (i+1) % 10 == 0 and i < len(paragraphs) - 1:
        #        page_break = soup.new_tag('div')
        #        page_break['style'] = 'page-break-after: always; break-after: page;'
        #        p.insert_after(page_break)

        # 4. ƒê·∫£m b·∫£o kho·∫£ng c√°ch gi·ªØa c√°c ƒëo·∫°n
        for p in soup.find_all('p'):
            p['style'] = 'margin-top: 0.5em; margin-bottom: 0.5em;'

        # 5. Chuy·ªÉn ƒë·ªïi c√°c th·∫ª ph·ª©c t·∫°p th√†nh th·∫ª ƒë∆°n gi·∫£n h∆°n
        for tag in soup.find_all(['div', 'span']):
            if not tag.find_all(True):  # N·∫øu kh√¥ng c√≥ th·∫ª con
                new_tag = soup.new_tag('p')
                new_tag.string = tag.get_text()
                tag.replace_with(new_tag)

        # 6. Chu·∫©n h√≥a c√°c th·∫ª tr·ªëng
        for tag in soup.find_all():
            if len(tag.get_text(strip=True)) == 0 and tag.name not in ['br', 'img', 'hr']:
                tag.decompose()

        # 7. ƒê·∫£m b·∫£o c√°c k√Ω t·ª± ƒë·∫∑c bi·ªát ƒë∆∞·ª£c hi·ªÉn th·ªã ƒë√∫ng
        for entity in soup.find_all(string=lambda text: '&' in text):
            new_text = entity.replace('&nbsp;', ' ')
            entity.replace_with(new_text)

        return str(soup)
    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói khi t·ªëi ∆∞u h√≥a HTML: {e}")
        traceback.print_exc()
        return html_content  # Tr·∫£ v·ªÅ nguy√™n b·∫£n n·∫øu c√≥ l·ªói

# H√†m l·∫•y n·ªôi dung ch∆∞∆°ng t·ª´ Metruyenchu
def get_mtc_chapter_content(url, chapter_number, chapter_title=None, novel_title=""):
    try:
        chapter_url = url + "/chuong-" + str(chapter_number)
        html = make_request(chapter_url, is_mtc=True)
        soup = BeautifulSoup(html, 'html.parser')

        # L·∫•y ti√™u ƒë·ªÅ ch∆∞∆°ng
        title_elem = soup.select_one('h2')
        base_title = title_elem.text.strip() if title_elem and title_elem.text else "Ch∆∞∆°ng " + str(chapter_number)

        # S·ª≠ d·ª•ng ti√™u ƒë·ªÅ t·ª´ API n·∫øu c√≥
        if chapter_title:
            base_title = chapter_title

        # L·∫•y n·ªôi dung ch∆∞∆°ng
        content_elem = soup.select_one('[data-x-bind="ChapterContent"]')
        content = ""

        if content_elem:
            content = content_elem.get_text('\n', strip=True)

        if not content or len(content.strip()) == 0:
            # L∆∞u file HTML ƒë·ªÉ debug
            queue_debug_save(novel_title, chapter_info, html)

            # Still no content, use fallback
            content = "Kh√¥ng c√≥ n·ªôi dung. Ch∆∞∆°ng n√†y c√≥ th·ªÉ b·ªã kh√≥a ho·∫∑c kh√¥ng t·ªìn t·∫°i."
            print(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y n·ªôi dung cho ch∆∞∆°ng {chapter_number}: N·ªôi dung c√≥ th·ªÉ b·ªã kho√° ho·∫∑c kh√¥ng t·ªìn t·∫°i, s·ª≠ d·ª•ng n·ªôi dung m·∫∑c ƒë·ªãnh")

        # Tr√≠ch xu·∫•t ti√™u ƒë·ªÅ t·ªët h∆°n n·∫øu c√≥ th·ªÉ
        title = extract_chapter_title(chapter_number, content, base_title)

        # Format l·∫°i n·ªôi dung html
        if content_elem:
            # X·ª≠ l√Ω c√°c th·∫ª p v√† br
            for p in content_elem.find_all('p'):
                p.insert_after(soup.new_tag('br'))
            content_html = str(content_elem)

            # T·ªëi ∆∞u h√≥a HTML cho e-reader
            content_html = optimize_html_for_ereader(content_html)
        else:
            content_html = "<p>" + content + "</p>"

        # In th√¥ng tin c√≥ ƒë∆∞·ª£c
        print("‚úÖ ƒê√£ t·∫£i ch∆∞∆°ng " + str(chapter_number) + ": " + title + " - ƒê·ªô d√†i: " + str(len(content)) + " k√Ω t·ª±")

        return {
            'title': title,
            'content': content,
            'content_html': content_html
        }
    except Exception as e:
        print("‚ùå L·ªói khi t·∫£i ch∆∞∆°ng " + str(chapter_number) + " t·ª´ Metruyenchu: " + str(e))
        traceback.print_exc()
        raise

# H√†m l·∫•y n·ªôi dung ch∆∞∆°ng t·ª´ Tangthuvien
def get_ttv_chapter_content(chapter_info, novel_title=""):
    try:
        chapter_number = chapter_info['index']
        chapter_url = chapter_info['url']
        chapter_title = chapter_info['name']

        # L·∫•y HTML t·ª´ trang
        html = make_request(chapter_url, is_mtc=False)

        # Ph√¢n t√≠ch n·ªôi dung
        soup = BeautifulSoup(html, 'html.parser')

        # X√≥a h·∫øt n·ªôi dung trong th·∫ª head ƒë·ªÉ gi·∫£m k√≠ch th∆∞·ªõc file debug
        if soup.head:
            soup.head.clear()
            soup.head.append(soup.new_tag('title'))
            soup.head.title.string = f"Debug HTML - Ch∆∞∆°ng {chapter_number}"

        # N·ªôi dung truy·ªán - th·ª≠ v·ªõi selector ch√≠nh
        content_elem = soup.select_one('.box-chap')
        content = ""
        content_html = ""

        # N·∫øu kh√¥ng t√¨m th·∫•y selector ch√≠nh, th·ª≠ v·ªõi selector thay th·∫ø
        if not content_elem or not content_elem.text.strip():
            content_blocks = soup.select('p.content-block')

            if content_blocks:
                print(f"‚ÑπÔ∏è S·ª≠ d·ª•ng selector thay th·∫ø cho ch∆∞∆°ng {chapter_number}")

                # T·∫°o n·ªôi dung t·ª´ c√°c th·∫ª p.content-block
                content = "\n".join([block.get_text(strip=True) for block in content_blocks])

                # T·∫°o HTML m·ªõi v·ªõi c√°c th·∫ª p
                content_container = soup.new_tag('div')
                content_container['class'] = 'chapter-content'

                for block in content_blocks:
                    p = soup.new_tag('p')
                    p.string = block.get_text(strip=True)
                    content_container.append(p)

                    # Th√™m th·∫ª br sau m·ªói ƒëo·∫°n ƒë·ªÉ ƒë·∫£m b·∫£o xu·ªëng d√≤ng trong EPUB
                    br = soup.new_tag('br')
                    content_container.append(br)

                content_elem = content_container
                content_html = str(content_container)
            else:
                # V·∫´n kh√¥ng t√¨m th·∫•y n·ªôi dung
                content_elem = None

        # X·ª≠ l√Ω n·∫øu t√¨m th·∫•y n·ªôi dung v·ªõi selector ch√≠nh
        if content_elem and not content:
            content = content_elem.get_text('\n', strip=True)

            # T·∫°o HTML m·ªõi t·ª´ vƒÉn b·∫£n v·ªõi c√°c k√Ω t·ª± xu·ªëng d√≤ng \n ƒë∆∞·ª£c chuy·ªÉn th√†nh th·∫ª p
            if content:
                # T√°ch c√°c ƒëo·∫°n theo k√Ω t·ª± xu·ªëng d√≤ng \n
                paragraphs = content.split('\n')

                # T·∫°o div ch·ª©a n·ªôi dung
                fixed_content_elem = soup.new_tag('div')
                fixed_content_elem['class'] = 'chapter-content'

                # Th√™m m·ªói ƒëo·∫°n vƒÉn v√†o m·ªôt th·∫ª p ri√™ng
                for paragraph in paragraphs:
                    # B·ªè qua c√°c d√≤ng tr·ªëng
                    if paragraph.strip():
                        p = soup.new_tag('p')
                        p.string = paragraph.strip()
                        fixed_content_elem.append(p)

                content_html = str(fixed_content_elem)
            else:
                content_html = "<div class='chapter-content'></div>"

        # N·∫øu kh√¥ng l·∫•y ƒë∆∞·ª£c n·ªôi dung, l∆∞u file HTML ƒë·ªÉ debug
        if not content or len(content.strip()) == 0:
            # L∆∞u file HTML ƒë·ªÉ debug
            clean_html = str(soup)
            queue_debug_save(novel_title, chapter_info, clean_html)

            # S·ª≠ d·ª•ng n·ªôi dung m·∫∑c ƒë·ªãnh
            content = "Kh√¥ng c√≥ n·ªôi dung. Ch∆∞∆°ng n√†y c√≥ th·ªÉ b·ªã kh√≥a ho·∫∑c kh√¥ng t·ªìn t·∫°i."
            print(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y n·ªôi dung cho ch∆∞∆°ng {chapter_number}: N·ªôi dung c√≥ th·ªÉ b·ªã kho√° ho·∫∑c kh√¥ng t·ªìn t·∫°i, ƒë√£ l∆∞u HTML ƒë·ªÉ debug")
            content_html = "<p>" + content + "</p>"

        # N·∫øu ch∆∞a c√≥ content_html (hi·∫øm g·∫∑p)
        if not content_html:
            content_html = "<p>" + content.replace("\n\n", "</p><p>") + "</p>"

        # Tr√≠ch xu·∫•t ti√™u ƒë·ªÅ t·ªët h∆°n n·∫øu c√≥ th·ªÉ
        title = extract_chapter_title(chapter_number, content, chapter_title)

        # T·ªëi ∆∞u h√≥a HTML cho e-reader
        content_html = optimize_html_for_ereader(content_html)

        # In th√¥ng tin c√≥ ƒë∆∞·ª£c
        print("‚úÖ ƒê√£ t·∫£i ch∆∞∆°ng " + str(chapter_number) + ": " + title + " - ƒê·ªô d√†i: " + str(len(content)) + " k√Ω t·ª±")

        return {
            'title': title,
            'content': content,
            'content_html': content_html
        }
    except Exception as e:
        print("‚ùå L·ªói khi t·∫£i ch∆∞∆°ng " + str(chapter_number) + " t·ª´ Tangthuvien: " + str(e))
        traceback.print_exc()
        raise

# H√†m l·∫•y n·ªôi dung ch∆∞∆°ng
def get_chapter_content(url, chapter_info, site_type, novel_title):
    if site_type == 'metruyenchu':
        return get_mtc_chapter_content(url, chapter_info['index'], chapter_info.get('name'), novel_title)
    elif site_type == 'tangthuvien':
        return get_ttv_chapter_content(chapter_info, novel_title)
    else:
        raise ValueError(f"Kh√¥ng h·ªó tr·ª£ lo·∫°i trang web: {site_type}")

# H√†m t·∫°o EPUB m·ªõi
def create_epub(novel_info):
    try:
        print("üìô B·∫Øt ƒë·∫ßu t·∫°o file EPUB m·ªõi...")
        book = epub.EpubBook()

        # Th√™m metadata
        book_id = str(uuid.uuid4())
        book.set_identifier(book_id)
        book.set_title(novel_info['title'])
        book.set_language('vi')
        book.add_author(novel_info['author'])
        print("üìù ƒê√£ th√™m metadata (id: " + book_id[:8] + "...)")

        # Th√™m metadata cho e-reader
        book.add_metadata(None, 'meta', '', {'name': 'fixed-layout', 'content': 'false'})
        book.add_metadata(None, 'meta', '', {'name': 'book-type', 'content': 'text'})
        book.add_metadata(None, 'meta', '', {'name': 'viewport', 'content': 'width=device-width, height=device-height'})

        # T·∫£i v√† th√™m ·∫£nh b√¨a
        if novel_info['cover_url']:
            try:
                print("üñºÔ∏è ƒêang t·∫£i ·∫£nh b√¨a t·ª´: " + novel_info['cover_url'])
                headers = {
                    'user-agent': generate_user_agent(),
                    'referer': 'https://metruyencv.com/'
                }
                cover_response = requests.get(novel_info['cover_url'], headers=headers)
                cover_response.raise_for_status()
                cover_content = cover_response.content

                # X√°c ƒë·ªãnh ƒë·ªãnh d·∫°ng ·∫£nh
                parsed_url = urlparse(novel_info['cover_url'])
                path = unquote(parsed_url.path)
                _, ext = os.path.splitext(path)
                if not ext:
                    ext = '.jpg'  # M·∫∑c ƒë·ªãnh l√† jpg n·∫øu kh√¥ng c√≥ extension

                book.set_cover("cover" + ext, cover_content)
                print("‚úÖ ƒê√£ th√™m ·∫£nh b√¨a (" + str(len(cover_content)) + " bytes)")
            except Exception as e:
                print("‚ö†Ô∏è L·ªói khi t·∫£i ·∫£nh b√¨a: " + str(e))
                traceback.print_exc()

        # Th√™m trang gi·ªõi thi·ªáu
        print("üìÑ T·∫°o trang gi·ªõi thi·ªáu...")
        intro = epub.EpubHtml(title='Gi·ªõi thi·ªáu', file_name='intro.xhtml')
        intro.id = 'intro'  # ƒê·∫∑t thu·ªôc t√≠nh id

        synopsis_html = '<p>Kh√¥ng c√≥ gi·ªõi thi·ªáu</p>'
        if novel_info['synopsis']:
            synopsis_html = '<p>' + novel_info['synopsis'].replace('\n', '</p><p>') + '</p>'

        intro_content = """
        <html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops">
        <head>
            <title>Gi·ªõi thi·ªáu</title>
            <meta charset="utf-8"/>
            <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
        </head>
        <body>
            <h1>""" + novel_info['title'] + """</h1>
            <p><strong>T√°c gi·∫£:</strong> """ + novel_info['author'] + """</p>
            <h2>Gi·ªõi thi·ªáu</h2>
            """ + synopsis_html + """
        </body>
        </html>
        """
        intro.content = intro_content
        book.add_item(intro)

        # Th√™m CSS t·ªëi ∆∞u cho e-reader
        print("üé® Th√™m stylesheet...")
        style = """
        @namespace epub "http://www.idpf.org/2007/ops";

        html, body {
            margin: 0;
            padding: 0;
            font-family: serif;
            line-height: 1.5;
            text-align: justify;
            hyphens: auto;
            -webkit-hyphens: auto;
            -epub-hyphens: auto;
        }

        body {
            padding: 0% 3% 0% 3%;
            font-size: 1em;
            background-color: transparent;
        }

        h1, h2, h3, h4 {
            text-align: center;
            font-weight: bold;
            margin: 1em 0;
            page-break-after: avoid;
            page-break-inside: avoid;
            break-after: avoid;
        }

        h1 { font-size: 1.5em; }
        h2 { font-size: 1.3em; }

        p {
            margin: 0;
            padding: 0;
            text-indent: 1.5em;
            text-align: justify;
            orphans: 2;
            widows: 2;
            line-height: 1.5em;
        }

        p + p {
            margin-top: 0.3em;
        }

        div.page-break {
            page-break-after: always;
            break-after: page;
        }
        """
        css = epub.EpubItem(uid="style", file_name="style/style.css", media_type="text/css", content=style)
        book.add_item(css)

        # Th√™m nav
        book.add_item(epub.EpubNcx())
        book.add_item(epub.EpubNav())

        print("‚úÖ ƒê√£ t·∫°o xong c·∫•u tr√∫c EPUB c∆° b·∫£n")
        return book, intro
    except Exception as e:
        print("‚ùå L·ªói khi t·∫°o file EPUB: " + str(e))
        traceback.print_exc()
        raise

# H√†m s·ª≠a c√°c t·ªáp ƒëi·ªÅu h∆∞·ªõng v·ªõi ti√™u ƒë·ªÅ ch√≠nh x√°c
def fix_navigation_files(book, is_temp):
    """S·ª≠a c√°c t·ªáp ƒëi·ªÅu h∆∞·ªõng ƒë·ªÉ ƒë·∫£m b·∫£o t·∫•t c·∫£ c√°c ch∆∞∆°ng c√≥ ti√™u ƒë·ªÅ ph√π h·ª£p"""
    try:
        # L·∫•y t·∫•t c·∫£ ch∆∞∆°ng v√† tr√≠ch xu·∫•t ti√™u ƒë·ªÅ ƒë·∫ßy ƒë·ªß t·ª´ n·ªôi dung
        chapter_titles = {}
        for item in book.items:
            if isinstance(item, epub.EpubHtml) and hasattr(item, 'id') and item.id and item.id.startswith('chapter_'):
                try:
                    chapter_num = int(item.id.split('_')[1])

                    # ∆Øu ti√™n tr√≠ch xu·∫•t ti√™u ƒë·ªÅ t·ª´ n·ªôi dung HTML
                    full_title = None
                    if hasattr(item, 'content') and item.content:
                        full_title = extract_title_from_html(item.content)

                    # N·∫øu kh√¥ng t√¨m th·∫•y t·ª´ HTML, s·ª≠ d·ª•ng ti√™u ƒë·ªÅ c√≥ s·∫µn
                    if not full_title and hasattr(item, 'title') and item.title:
                        full_title = item.title

                    # N·∫øu v·∫´n kh√¥ng c√≥, t·∫°o ti√™u ƒë·ªÅ m·∫∑c ƒë·ªãnh
                    if not full_title:
                        full_title = f"Ch∆∞∆°ng {chapter_num}"

                    # L∆∞u l·∫°i ti√™u ƒë·ªÅ tr√≠ch xu·∫•t ƒë∆∞·ª£c
                    chapter_titles[chapter_num] = full_title

                    # C·∫≠p nh·∫≠t l·∫°i ti√™u ƒë·ªÅ ch∆∞∆°ng
                    item.title = full_title

                except Exception as e:
                    print(f"‚ö†Ô∏è L·ªói khi x·ª≠ l√Ω ch∆∞∆°ng {item.id}: {e}")

        if not chapter_titles:
            print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y ch∆∞∆°ng n√†o ƒë·ªÉ c·∫≠p nh·∫≠t ƒëi·ªÅu h∆∞·ªõng")
            return False

        if not is_temp:
            print(f"üìö T√¨m th·∫•y {len(chapter_titles)} ch∆∞∆°ng c√≥ ti√™u ƒë·ªÅ ƒë·ªÉ c·∫≠p nh·∫≠t ƒëi·ªÅu h∆∞·ªõng")

        # T·∫°o n·ªôi dung nav.xhtml m·ªõi t·ª´ ƒë·∫ßu n·∫øu c·∫ßn
        nav_content = """<?xml version='1.0' encoding='utf-8'?>
        <!DOCTYPE html>
        <html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" lang="vi" xml:lang="vi">
          <head>
            <title>{title}</title>
            <meta charset="utf-8"/>
          </head>
          <body>
            <nav epub:type="toc" id="id" role="doc-toc">
              <h2>{title}</h2>
              <ol>
                <li>
                  <a href="intro.xhtml">Gi·ªõi thi·ªáu</a>
                </li>
                {chapter_items}
              </ol>
            </nav>
          </body>
        </html>
        """

        # T·∫°o n·ªôi dung toc.ncx m·ªõi t·ª´ ƒë·∫ßu n·∫øu c·∫ßn
        toc_content = """<?xml version='1.0' encoding='utf-8'?>
        <ncx xmlns="http://www.daisy.org/z3986/2005/ncx/" version="2005-1">
          <head>
            <meta content="{uuid}" name="dtb:uid"/>
            <meta content="0" name="dtb:depth"/>
            <meta content="0" name="dtb:totalPageCount"/>
            <meta content="0" name="dtb:maxPageNumber"/>
          </head>
          <docTitle>
            <text>{title}</text>
          </docTitle>
          <navMap>
            <navPoint id="intro">
              <navLabel>
                <text>Gi·ªõi thi·ªáu</text>
              </navLabel>
              <content src="intro.xhtml"/>
            </navPoint>
            {chapter_items}
          </navMap>
        </ncx>
        """

        # T√¨m v√† c·∫≠p nh·∫≠t t·ªáp nav.xhtml
        nav_item = None
        for item in book.items:
            if isinstance(item, epub.EpubHtml) and item.file_name == 'nav.xhtml':
                nav_item = item
                break

        title = book.title if hasattr(book, 'title') else "Truy·ªán EPUB"

        if nav_item:
            try:
                if hasattr(nav_item, 'content') and nav_item.content:
                    soup = BeautifulSoup(nav_item.content, 'html.parser')
                    links = soup.select('nav ol li a')

                    for link in links:
                        href = link.get('href', '')
                        if href.startswith('chapter_') and href.endswith('.xhtml'):
                            try:
                                chapter_num = int(href.split('_')[1].split('.')[0])
                                if chapter_num in chapter_titles and chapter_titles[chapter_num]:
                                    link.string = chapter_titles[chapter_num]
                            except:
                                pass

                    nav_item.content = str(soup)
                    if not is_temp:
                        print("‚úÖ ƒê√£ c·∫≠p nh·∫≠t nav.xhtml v·ªõi ti√™u ƒë·ªÅ ch∆∞∆°ng ch√≠nh x√°c")
                else:
                    # T·∫°o n·ªôi dung nav.xhtml m·ªõi
                    chapter_items = ""
                    for num in sorted(chapter_titles.keys()):
                        chapter_items += f"""
                        <li>
                          <a href="chapter_{num}.xhtml">{chapter_titles[num]}</a>
                        </li>"""

                    nav_item.content = nav_content.format(
                        title=title,
                        chapter_items=chapter_items
                    )
                    if not is_temp:
                        print("‚úÖ ƒê√£ t·∫°o m·ªõi n·ªôi dung nav.xhtml")
            except Exception as e:
                print(f"‚ö†Ô∏è L·ªói khi c·∫≠p nh·∫≠t nav.xhtml: {e}")
                traceback.print_exc()
        else:
            print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y nav.xhtml trong EPUB")

        # T√¨m v√† c·∫≠p nh·∫≠t t·ªáp toc.ncx
        toc_item = None
        for item in book.items:
            if item.file_name == 'toc.ncx':
                toc_item = item
                break

        if toc_item:
            try:
                if hasattr(toc_item, 'content') and toc_item.content:
                    soup = BeautifulSoup(toc_item.content, 'xml')
                    navpoints = soup.select('navPoint')

                    for navpoint in navpoints:
                        nav_id = navpoint.get('id', '')
                        if nav_id.startswith('chapter_'):
                            try:
                                chapter_num = int(nav_id.split('_')[1])
                                if chapter_num in chapter_titles and chapter_titles[chapter_num]:
                                    text_tag = navpoint.select_one('navLabel text')
                                    if text_tag:
                                        text_tag.string = chapter_titles[chapter_num]
                            except:
                                pass

                    toc_item.content = str(soup)
                    if not is_temp:
                        print("‚úÖ ƒê√£ c·∫≠p nh·∫≠t toc.ncx v·ªõi ti√™u ƒë·ªÅ ch∆∞∆°ng ch√≠nh x√°c")
                else:
                    # T·∫°o n·ªôi dung toc.ncx m·ªõi
                    chapter_items = ""
                    for num in sorted(chapter_titles.keys()):
                        chapter_items += f"""
                        <navPoint id="chapter_{num}">
                          <navLabel>
                            <text>{chapter_titles[num]}</text>
                          </navLabel>
                          <content src="chapter_{num}.xhtml"/>
                        </navPoint>"""

                    book_uuid = book.get_metadata('DC', 'identifier')[0][0] if hasattr(book, 'get_metadata') else str(uuid.uuid4())

                    toc_item.content = toc_content.format(
                        uuid=book_uuid,
                        title=title,
                        chapter_items=chapter_items
                    )
                    if not is_temp:
                        print("‚úÖ ƒê√£ t·∫°o m·ªõi n·ªôi dung toc.ncx")
            except Exception as e:
                print(f"‚ö†Ô∏è L·ªói khi c·∫≠p nh·∫≠t toc.ncx: {e}")
                traceback.print_exc()
        else:
            print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y toc.ncx trong EPUB")

        return True
    except Exception as e:
        print(f"‚ùå L·ªói khi s·ª≠a t·ªáp ƒëi·ªÅu h∆∞·ªõng: {e}")
        traceback.print_exc()
        return False

# H√†m ƒë·ªçc EPUB ƒë√£ t·ªìn t·∫°i
def load_existing_epub(epub_path):
    try:
        print("üìö ƒêang ƒë·ªçc file EPUB hi·ªán c√≥: " + epub_path)
        book = epub.read_epub(epub_path)

        # T√¨m s·ªë ch∆∞∆°ng ƒë√£ c√≥
        spine_items = [item for item in book.spine if isinstance(item, tuple) and item[0] != 'nav']

        # Find chapters by file name pattern instead of relying on id attribute
        chapter_items = [item for item in book.items if isinstance(item, epub.EpubHtml)
                         and item.file_name.startswith('chapter_') and item.file_name.endswith('.xhtml')]

        # Ensure all chapters have proper IDs
        for item in chapter_items:
            if not hasattr(item, 'id') or not item.id:
                try:
                    chapter_num = int(item.file_name.split('_')[1].split('.')[0])
                    item.id = 'chapter_' + str(chapter_num)
                except Exception as e:
                    print("‚ö†Ô∏è L·ªói khi t·∫°o ID cho chapter: " + str(e))

        # B√¢y gi·ªù tr√≠ch xu·∫•t ti√™u ƒë·ªÅ ƒë·∫ßy ƒë·ªß t·ª´ n·ªôi dung HTML
        for item in chapter_items:
            try:
                if hasattr(item, 'content') and item.content:
                    full_title = extract_title_from_html(item.content)
                    if full_title:
                        item.title = full_title
                        print(f"üìù ƒê√£ tr√≠ch xu·∫•t ti√™u ƒë·ªÅ t·ª´ HTML: {full_title}")

                    # T·ªëi ∆∞u h√≥a HTML cho e-reader
                    item.content = optimize_html_for_ereader(item.content)
            except Exception as e:
                print(f"‚ö†Ô∏è L·ªói khi tr√≠ch xu·∫•t ti√™u ƒë·ªÅ t·ª´ HTML: {e}")

        # Now filter items with IDs
        chapter_items = [item for item in chapter_items if hasattr(item, 'id') and item.id.startswith('chapter_')]

        print("üìä ƒê√£ t√¨m th·∫•y " + str(len(chapter_items)) + " ch∆∞∆°ng trong file")

        # L·∫•y trang gi·ªõi thi·ªáu
        intro = None
        for item in book.items:
            if isinstance(item, epub.EpubHtml) and item.file_name == 'intro.xhtml':
                intro = item
                # Ensure intro has an id
                if not hasattr(intro, 'id') or not intro.id:
                    intro.id = 'intro'
                print("üìÑ ƒê√£ t√¨m th·∫•y trang gi·ªõi thi·ªáu")
                break

        if intro is None:
            print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y trang gi·ªõi thi·ªáu trong file EPUB")

        # T√¨m ch∆∞∆°ng cu·ªëi c√πng
        max_chapter = 0
        for item in chapter_items:
            # L·∫•y s·ªë ch∆∞∆°ng t·ª´ id (chapter_X)
            try:
                if hasattr(item, 'id') and item.id:
                    chapter_num = int(item.id.split('_')[1])
                else:
                    # Fallback to file_name if id is not available
                    chapter_num = int(item.file_name.split('_')[1].split('.')[0])
                max_chapter = max(max_chapter, chapter_num)
            except Exception as e:
                print("‚ö†Ô∏è L·ªói khi ƒë·ªçc s·ªë ch∆∞∆°ng t·ª´ " + str(getattr(item, 'id', item.file_name)) + ": " + str(e))

        print("üìå Ch∆∞∆°ng cu·ªëi c√πng t√¨m th·∫•y: Ch∆∞∆°ng " + str(max_chapter))

        # S·ª≠a t·ªáp ƒëi·ªÅu h∆∞·ªõng
        fix_navigation_files(book, True)

        return book, intro, max_chapter
    except Exception as e:
        print("‚ùå L·ªói khi ƒë·ªçc file EPUB " + epub_path + ": " + str(e))
        traceback.print_exc()
        raise

# H√†m th√™m ch∆∞∆°ng v√†o EPUB
def add_chapter_to_epub(book, chapter_data, chapter_number):
    try:
        chapter_id = 'chapter_' + str(chapter_number)

        # L·∫•y ti√™u ƒë·ªÅ t·ªët h∆°n t·ª´ n·ªôi dung n·∫øu c√≥
        title = extract_chapter_title(chapter_number, chapter_data['content'], chapter_data['title'])

        chapter = epub.EpubHtml(title=title, file_name='chapter_' + str(chapter_number) + '.xhtml')
        chapter.id = chapter_id  # ƒê·∫∑t thu·ªôc t√≠nh id sau khi t·∫°o

        content_html = "<p>Kh√¥ng c√≥ n·ªôi dung</p>"
        if 'content_html' in chapter_data:
            content_html = chapter_data['content_html']

        # Chu·∫©n b·ªã n·ªôi dung HTML t·ªëi ∆∞u cho e-reader
        chapter_content = """
        <html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops">
        <head>
            <title>""" + title + """</title>
            <meta charset="utf-8"/>
            <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
        </head>
        <body>
            """ + content_html + """
        </body>
        </html>
        """
        chapter.content = chapter_content
        book.add_item(chapter)

        return chapter
    except Exception as e:
        print("‚ùå L·ªói khi th√™m ch∆∞∆°ng " + str(chapter_number) + " v√†o EPUB: " + str(e))
        traceback.print_exc()
        raise

# H√†m chia nh·ªè ch∆∞∆°ng d√†i th√†nh nhi·ªÅu ph·∫ßn
def split_large_chapters(book, is_temp):
    """Chia nh·ªè c√°c ch∆∞∆°ng qu√° d√†i ƒë·ªÉ tr√°nh v·∫•n ƒë·ªÅ hi·ªáu su·∫•t tr√™n e-reader"""
    try:
        modified = False
        large_chapters = []

        # T√¨m c√°c ch∆∞∆°ng qu√° d√†i
        for item in book.items:
            if isinstance(item, epub.EpubHtml) and hasattr(item, 'id') and item.id.startswith('chapter_'):
                if hasattr(item, 'content') and item.content and len(item.content) > 100000:  # ~100KB
                    large_chapters.append(item)

        if not large_chapters:
            return False

        if not is_temp:
            print(f"üìè ƒê√£ t√¨m th·∫•y {len(large_chapters)} ch∆∞∆°ng qu√° d√†i c·∫ßn chia nh·ªè")

        # X·ª≠ l√Ω t·ª´ng ch∆∞∆°ng d√†i
        for chapter in large_chapters:
            try:
                chapter_num = int(chapter.id.split('_')[1])
                soup = BeautifulSoup(chapter.content, 'html.parser')

                # L·∫•y ph·∫ßn body
                body = soup.find('body')
                if not body:
                    continue

                # L·∫•y ti√™u ƒë·ªÅ
                title_tag = soup.find('h2')
                title = title_tag.get_text() if title_tag else chapter.title

                # L·∫•y t·∫•t c·∫£ ƒëo·∫°n vƒÉn
                paragraphs = body.find_all('p')

                if len(paragraphs) < 20:  # Kh√¥ng ƒë·ªß ƒëo·∫°n ƒë·ªÉ chia
                    continue

                # Chia th√†nh c√°c ph·∫ßn
                parts = []
                part_size = max(10, len(paragraphs) // 3)  # √çt nh·∫•t 10 ƒëo·∫°n m·ªói ph·∫ßn, t·ªëi ƒëa 3 ph·∫ßn

                for i in range(0, len(paragraphs), part_size):
                    part_paragraphs = paragraphs[i:i+part_size]
                    if not part_paragraphs:
                        continue

                    part_soup = BeautifulSoup("""
                    <html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops">
                    <head>
                        <title></title>
                        <meta charset="utf-8"/>
                    </head>
                    <body></body>
                    </html>
                    """, 'html.parser')

                    part_soup.title.string = title

                    # Th√™m ti√™u ƒë·ªÅ v√†o ph·∫ßn ƒë·∫ßu ti√™n
                    if i == 0 and title_tag:
                        part_soup.body.append(title_tag)

                    # Th√™m ph·ª• ƒë·ªÅ cho c√°c ph·∫ßn sau
                    else:
                        part_title = part_soup.new_tag('h3')
                        part_title.string = f"{title} (ti·∫øp theo)"
                        part_soup.body.append(part_title)

                    # Th√™m c√°c ƒëo·∫°n vƒÉn
                    for p in part_paragraphs:
                        part_soup.body.append(p)

                    # Th√™m ng·∫Øt trang cu·ªëi ph·∫ßn
                    page_break = part_soup.new_tag('div')
                    page_break['style'] = 'page-break-after: always; break-after: page;'
                    part_soup.body.append(page_break)

                    parts.append(str(part_soup))

                if len(parts) <= 1:  # Kh√¥ng c·∫ßn chia n·∫øu ch·ªâ c√≥ 1 ph·∫ßn
                    continue

                # T·∫°o c√°c ch∆∞∆°ng con
                for i, part_content in enumerate(parts):
                    sub_id = f"chapter_{chapter_num}_{i+1}"
                    sub_filename = f"chapter_{chapter_num}_{i+1}.xhtml"

                    # ƒê·∫∑t t√™n cho ph·∫ßn
                    if i == 0:
                        sub_title = title
                    else:
                        sub_title = f"{title} (ph·∫ßn {i+1})"

                    sub_chapter = epub.EpubHtml(title=sub_title, file_name=sub_filename)
                    sub_chapter.id = sub_id
                    sub_chapter.content = part_content
                    book.add_item(sub_chapter)

                # Th√™m v√†o spine thay th·∫ø ch∆∞∆°ng g·ªëc
                spine_index = book.spine.index(chapter) if chapter in book.spine else -1
                if spine_index > 0:
                    # X√≥a ch∆∞∆°ng g·ªëc
                    book.spine.pop(spine_index)

                    # Th√™m c√°c ch∆∞∆°ng con v√†o v·ªã tr√≠ ƒë√≥
                    for i in range(len(parts)):
                        sub_id = f"chapter_{chapter_num}_{i+1}"
                        for item in book.items:
                            if hasattr(item, 'id') and item.id == sub_id:
                                book.spine.insert(spine_index + i, item)

                # ƒê√°nh d·∫•u ƒë√£ s·ª≠a ƒë·ªïi
                modified = True
                if not is_temp:
                    print(f"‚úÇÔ∏è ƒê√£ chia ch∆∞∆°ng {chapter_num} th√†nh {len(parts)} ph·∫ßn")

            except Exception as e:
                print(f"‚ö†Ô∏è L·ªói khi chia nh·ªè ch∆∞∆°ng {chapter.id}: {e}")
                traceback.print_exc()

        return modified
    except Exception as e:
        print(f"‚ùå L·ªói khi chia nh·ªè ch∆∞∆°ng: {e}")
        traceback.print_exc()
        return False

# H√†m l∆∞u EPUB
def save_epub(book, intro, chapters, output_path, is_temp):
    try:
        if not is_temp:
            print("üíæ ƒêang l∆∞u EPUB v√†o: " + output_path)

        # X√≥a spine c≈© v√† t·∫°o m·ªõi ƒë·ªÉ ƒë·∫£m b·∫£o th·ª© t·ª± ƒë√∫ng
        book.spine = [('nav', 'nav')]
        book.spine.append(intro)

        # Th√™m chapters v√†o spine theo th·ª© t·ª±
        # ƒê·∫£m b·∫£o t·∫•t c·∫£ c√°c ch∆∞∆°ng c√≥ thu·ªôc t√≠nh id
        for chapter in chapters:
            if not hasattr(chapter, 'id') or not chapter.id:
                chapter_num = int(chapter.file_name.split('_')[1].split('.')[0])
                chapter.id = 'chapter_' + str(chapter_num)

            # ƒê·∫£m b·∫£o t·∫•t c·∫£ c√°c ch∆∞∆°ng c√≥ ti√™u ƒë·ªÅ ph√π h·ª£p
            if not hasattr(chapter, 'title') or not chapter.title or chapter.title == "":
                chapter_num = int(chapter.id.split('_')[1])
                # Tr√≠ch xu·∫•t ti√™u ƒë·ªÅ t·ª´ n·ªôi dung HTML n·∫øu c√≥
                if hasattr(chapter, 'content') and chapter.content:
                    full_title = extract_title_from_html(chapter.content)
                    if full_title:
                        chapter.title = full_title
                    else:
                        chapter.title = f"Ch∆∞∆°ng {chapter_num}"
                else:
                    chapter.title = f"Ch∆∞∆°ng {chapter_num}"

        # S·∫Øp x·∫øp ch∆∞∆°ng theo s·ªë th·ª© t·ª±
        try:
            sorted_chapters = sorted(chapters, key=lambda x: int(x.id.split('_')[1]))
        except Exception as e:
            print(f"‚ö†Ô∏è L·ªói khi s·∫Øp x·∫øp ch∆∞∆°ng: {e}")
            # Fallback: s·∫Øp x·∫øp theo t√™n file
            sorted_chapters = sorted(chapters,
                key=lambda x: int(re.search(r'chapter_(\d+)', x.file_name).group(1))
                    if re.search(r'chapter_(\d+)', x.file_name) else 0
            )

        for chapter in sorted_chapters:
            book.spine.append(chapter)

        if not is_temp:
            print("üìö T·ªïng s·ªë ch∆∞∆°ng trong spine: " + str(len(sorted_chapters)))

        # T·∫°o m·ª•c l·ª•c
        toc = [epub.Link('intro.xhtml', 'Gi·ªõi thi·ªáu', 'intro')]
        for chapter in sorted_chapters:
            toc.append(epub.Link(chapter.file_name, chapter.title, chapter.id))

        book.toc = toc

        if not is_temp:
            print("üìã ƒê√£ t·∫°o m·ª•c l·ª•c v·ªõi " + str(len(toc)) + " m·ª•c")

        # S·ª≠a t·ªáp ƒëi·ªÅu h∆∞·ªõng tr∆∞·ªõc khi l∆∞u
        fix_navigation_files(book, is_temp)

        # Chia nh·ªè c√°c ch∆∞∆°ng qu√° d√†i
        split_large_chapters(book, is_temp)

        # L∆∞u EPUB
        try:
            epub.write_epub(output_path, book, {})

            if not is_temp:
                print("‚úÖ ƒê√£ l∆∞u th√†nh c√¥ng EPUB t·∫°i: " + output_path)

            # Ki·ªÉm tra k√≠ch th∆∞·ªõc file
            if not is_temp:
                file_size = os.path.getsize(output_path)
                print("üìä K√≠ch th∆∞·ªõc file: " + str(round(file_size / (1024*1024), 2)) + " MB")

            return True
        except Exception as e:
            print("‚ùå L·ªói khi ghi file EPUB: " + str(e))
            traceback.print_exc()
            raise
    except Exception as e:
        print("‚ùå L·ªói khi l∆∞u EPUB: " + str(e))
        traceback.print_exc()
        raise

# H√†m ch√≠nh ƒë·ªÉ t·∫£i truy·ªán
def download_novel(url, start_chapter_index=None, end_chapter_index=None):

    # Start background saver thread
    saver_thread = threading.Thread(target=checkpoint_saver_thread, daemon=True)
    saver_thread.start()

    # Kh·ªüi ƒë·ªông thread l∆∞u debug
    debug_thread = threading.Thread(target=debug_save_thread, daemon=True)
    debug_thread.start()

    try:
        # L·∫•y th√¥ng tin truy·ªán
        print("üìö ƒêang l·∫•y th√¥ng tin truy·ªán...")
        novel_info = get_novel_info(url)

        # Ki·ªÉm tra xem c√≥ danh s√°ch ch∆∞∆°ng kh√¥ng
        if not novel_info['chapters_list']:
            print("‚ùå Kh√¥ng th·ªÉ l·∫•y danh s√°ch ch∆∞∆°ng")
            return None

        total_chapters = len(novel_info['chapters_list'])
        print(f"üìö T·ªïng s·ªë ch∆∞∆°ng: {total_chapters}")

        # L·∫•y lo·∫°i trang web
        site_type = novel_info['site_type']
        print(f"üåê Lo·∫°i trang web: {site_type}")

        # S·∫Øp x·∫øp ch∆∞∆°ng theo index
        sorted_chapters = sorted(novel_info['chapters_list'], key=lambda x: x.get('index', 0))

        # T√™n file epub
        epub_filename = novel_info['title'] + ".epub"
        local_epub_path = epub_filename
        temp_epub_path = os.path.join(temp_folder, epub_filename)
        final_epub_path = os.path.join(main_folder, epub_filename)

        # Ki·ªÉm tra n·∫øu file ƒë√£ t·ªìn t·∫°i
        book = None
        intro = None
        existing_chapters = []
        existing_epub = False

         # Ki·ªÉm tra file trong b·ªô nh·ªõ local tr∆∞·ªõc
        if os.path.exists(local_epub_path):
            print("üîç T√¨m th·∫•y file EPUB ·ªü local: " + local_epub_path)
            try:
                print("TODO: comment")
                # book, intro, _ = load_existing_epub(local_epub_path)
                # existing_epub = True
            except Exception as e:
                print(f"‚ö†Ô∏è Kh√¥ng th·ªÉ ƒë·ªçc file EPUB local ({e}), ki·ªÉm tra ti·∫øp c√°c v·ªã tr√≠ kh√°c")

        if not existing_epub:
            for check_path in [temp_epub_path, final_epub_path]:
                if os.path.exists(check_path):
                    print("üîç T√¨m th·∫•y file EPUB: " + check_path)
                    try:
                        print("TODO: comment")
                        # book, intro, _ = load_existing_epub(check_path)
                        # existing_epub = True
                        break
                    except Exception as e:
                        print(f"‚ö†Ô∏è Kh√¥ng th·ªÉ ƒë·ªçc file EPUB {check_path} ({e}), ti·∫øp t·ª•c ki·ªÉm tra")

        # N·∫øu truy·ªán ch∆∞a t·ªìn t·∫°i, t·∫°o m·ªõi
        if not existing_epub:
            print("üÜï T·∫°o file EPUB m·ªõi...")
            book, intro = create_epub(novel_info)
            existing_chapters = []
        else:
            # L·∫•y danh s√°ch chapters hi·ªán c√≥
            try:
                # T√¨m ch∆∞∆°ng b·∫±ng m·∫´u t√™n t·ªáp tr∆∞·ªõc
                existing_chapters = [item for item in book.items if isinstance(item, epub.EpubHtml)
                           and item.file_name.startswith('chapter_') and item.file_name.endswith('.xhtml')]

                # ƒê·∫£m b·∫£o t·∫•t c·∫£ c√°c ch∆∞∆°ng c√≥ ID ph√π h·ª£p
                for item in existing_chapters:
                    if not hasattr(item, 'id') or not item.id:
                        try:
                            chapter_num = int(item.file_name.split('_')[1].split('.')[0])
                            item.id = 'chapter_' + str(chapter_num)
                        except Exception as e:
                            print("‚ö†Ô∏è L·ªói khi t·∫°o ID cho chapter t·ª´ file_name: " + str(e))

                print("üìö ƒê√£ t√¨m th·∫•y " + str(len(existing_chapters)) + " ch∆∞∆°ng trong file EPUB hi·ªán c√≥")
            except Exception as e:
                print("‚ö†Ô∏è L·ªói khi l·∫•y danh s√°ch ch∆∞∆°ng t·ª´ file EPUB: " + str(e))
                traceback.print_exc()
                existing_chapters = []

        # Hi·ªÉn th·ªã l·ª±a ch·ªçn t·∫£i
        print("\n=== üì• L·ª∞A CH·ªåN T·∫¢I ===")
        print(f"1. T·∫£i t·∫•t c·∫£ c√°c ch∆∞∆°ng ({total_chapters} ch∆∞∆°ng)")
        print("2. T·∫£i t·ª´ ch∆∞∆°ng x ƒë·∫øn ch∆∞∆°ng y")
        download_choice = input("Nh·∫≠p l·ª±a ch·ªçn (1 ho·∫∑c 2, m·∫∑c ƒë·ªãnh 1): ").strip() or "1"

        if download_choice == "1":
            # T·∫£i t·∫•t c·∫£ ch∆∞∆°ng
            download_chapters = sorted_chapters
            print(f"üì• B·∫°n ƒë√£ ch·ªçn t·∫£i t·∫•t c·∫£ {len(download_chapters)} ch∆∞∆°ng")
        else:
            # T·∫£i t·ª´ ch∆∞∆°ng x ƒë·∫øn ch∆∞∆°ng y
            print(f"Danh s√°ch ch∆∞∆°ng c√≥ index t·ª´ 1 ƒë·∫øn {len(sorted_chapters)}")

            # N·∫øu ƒë√£ c√≥ tham s·ªë t·ª´ b√™n ngo√†i
            if start_chapter_index is not None and end_chapter_index is not None:
                start_idx = start_chapter_index
                end_idx = end_chapter_index
            else:
                # Nh·∫≠p t·ª´ ng∆∞·ªùi d√πng
                while True:
                    try:
                        start_idx = int(input(f"Nh·∫≠p index ch∆∞∆°ng b·∫Øt ƒë·∫ßu (1-{len(sorted_chapters)}): "))
                        if 1 <= start_idx <= len(sorted_chapters):
                            break
                        print(f"‚ö†Ô∏è Index ph·∫£i t·ª´ 1 ƒë·∫øn {len(sorted_chapters)}")
                    except ValueError:
                        print("‚ö†Ô∏è Vui l√≤ng nh·∫≠p m·ªôt s·ªë nguy√™n")

                while True:
                    try:
                        end_idx = int(input(f"Nh·∫≠p index ch∆∞∆°ng k·∫øt th√∫c ({start_idx}-{len(sorted_chapters)}): "))
                        if start_idx <= end_idx <= len(sorted_chapters):
                            break
                        print(f"‚ö†Ô∏è Index ph·∫£i t·ª´ {start_idx} ƒë·∫øn {len(sorted_chapters)}")
                    except ValueError:
                        print("‚ö†Ô∏è Vui l√≤ng nh·∫≠p m·ªôt s·ªë nguy√™n")

            # L·∫•y danh s√°ch ch∆∞∆°ng c·∫ßn t·∫£i
            download_chapters = sorted_chapters[start_idx-1:end_idx]
            print(f"üì• B·∫°n ƒë√£ ch·ªçn t·∫£i {len(download_chapters)} ch∆∞∆°ng t·ª´ index {start_idx} ƒë·∫øn {end_idx}")

        # Danh s√°ch c√°c ID ch∆∞∆°ng ƒë√£ t·ªìn t·∫°i
        existing_chapter_ids = set()
        for chapter in existing_chapters:
            try:
                chapter_id = int(chapter.id.split('_')[1])
                existing_chapter_ids.add(chapter_id)
            except Exception as e:
                print(f"‚ö†Ô∏è Kh√¥ng th·ªÉ x√°c ƒë·ªãnh ID ch∆∞∆°ng t·ª´ {chapter.id}: {e}")

        print(f"üîç ƒê√£ t√¨m th·∫•y {len(existing_chapter_ids)} ID ch∆∞∆°ng hi·ªán c√≥ trong EPUB")

        # L·ªçc danh s√°ch ch∆∞∆°ng c·∫ßn t·∫£i (ch·ªâ t·∫£i nh·ªØng ch∆∞∆°ng ch∆∞a c√≥)
        chapters_to_download = []
        for chapter_info in download_chapters:
            chapter_index = chapter_info.get('index')
            if chapter_index not in existing_chapter_ids:
                chapters_to_download.append(chapter_info)

        print(f"üì• C·∫ßn t·∫£i {len(chapters_to_download)} ch∆∞∆°ng m·ªõi")

        if not chapters_to_download:
            print("‚úÖ T·∫•t c·∫£ c√°c ch∆∞∆°ng ƒë√£ c√≥, kh√¥ng c·∫ßn t·∫£i th√™m")
            # V·∫´n l∆∞u EPUB ƒë·ªÉ c·∫≠p nh·∫≠t ƒëi·ªÅu h∆∞·ªõng v√† t·ªëi ∆∞u h√≥a
            save_epub(book, intro, existing_chapters, final_epub_path, False)
            return final_epub_path

        # Hi·ªÉn th·ªã th√¥ng tin c√°c ch∆∞∆°ng c·∫ßn t·∫£i
        print("\n=== üìù TH√îNG TIN T·∫¢I ===")
        print(f"üî¢ T·ªïng s·ªë ch∆∞∆°ng c·∫ßn t·∫£i: {len(chapters_to_download)}")
        if chapters_to_download:
            first_chapter = chapters_to_download[0]
            last_chapter = chapters_to_download[-1]
            print(f"üìå T·ª´: {first_chapter.get('name', 'Kh√¥ng t√™n')} (Index {first_chapter.get('index')})")
            print(f"üìå ƒê·∫øn: {last_chapter.get('name', 'Kh√¥ng t√™n')} (Index {last_chapter.get('index')})")

        new_chapters = []

        for chapter_info in tqdm(chapters_to_download, desc="ƒêang t·∫£i ch∆∞∆°ng"):
            try:
                chapter_index = chapter_info.get('index')

                # T·∫£i n·ªôi dung ch∆∞∆°ng theo lo·∫°i trang web
                chapter_data = get_chapter_content(url, chapter_info, site_type, novel_info['title'])

                # Th√™m ch∆∞∆°ng v√†o EPUB
                chapter = add_chapter_to_epub(book, chapter_data, chapter_index)
                new_chapters.append(chapter)

                # L∆∞u t·∫°m sau m·ªói 50 ch∆∞∆°ng
                if len(new_chapters) % checkpoint_interval == 0:
                    all_chapters = existing_chapters + new_chapters
                    save_queue.put((book, intro, all_chapters, temp_epub_path))
                    print(f"\n\nüì• ƒê√£ l√™n l·ªãch l∆∞u t·∫°m sau khi t·∫£i {len(new_chapters)} ch∆∞∆°ng\n\n")

                # Ngh·ªâ ng·∫Øn gi·ªØa c√°c request ƒë·ªÉ tr√°nh b·ªã ch·∫∑n
                delay_time = random.uniform(0.5, 1)
                delay(delay_time)
            except Exception as e:
                print(f"‚ùå L·ªói khi t·∫£i ch∆∞∆°ng index {chapter_index}: {e}")
                traceback.print_exc()
                # N·∫øu g·∫∑p l·ªói, l∆∞u tr·∫°ng th√°i hi·ªán t·∫°i v√† d·ª´ng
                try:
                    all_chapters = existing_chapters + new_chapters
                    save_queue.put((book, intro, all_chapters, temp_epub_path))
                    # Wait for save to complete in case of error
                    save_queue.join()
                    print(f"‚ö†Ô∏è ƒê√£ l∆∞u tr·∫°ng th√°i sau khi t·∫£i {len(new_chapters)} ch∆∞∆°ng")
                except Exception as save_err:
                    print(f"‚ùå‚ùå L·ªói khi l∆∞u tr·∫°ng th√°i sau khi g·∫∑p l·ªói: {save_err}")
                    traceback.print_exc()

        # K·∫øt h·ª£p ch∆∞∆°ng m·ªõi v√† ch∆∞∆°ng c≈©
        all_chapters = existing_chapters + new_chapters

        # L∆∞u b·∫£n cu·ªëi v√†o th∆∞ m·ª•c ch√≠nh
        print("üèÅ T·∫£i ho√†n t·∫•t, ƒëang l∆∞u EPUB cu·ªëi c√πng...")

        save_epub(book, intro, all_chapters, final_epub_path, False)

        # X√≥a file t·∫°m sau khi l∆∞u th√†nh c√¥ng
        if os.path.exists(final_epub_path):
            delete_temp_file(temp_epub_path)

        print("\nüéâüéâüéâ Ho√†n t·∫•t! Truy·ªán ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: " + final_epub_path)
        return final_epub_path
    except Exception as e:
        print("‚ùå L·ªói kh√¥ng x·ª≠ l√Ω ƒë∆∞·ª£c: " + str(e))
        traceback.print_exc()
        return None
    finally:
        # Signal thread to exit and wait for completion
        exit_event.set()
        debug_save_event.set()
        saver_thread.join(timeout=5.0)
        debug_thread.join(timeout=5.0)


# H√†m ch√≠nh
def main():
    try:
        print("=== ‚ú®‚ú®‚ú® TR√åNH T·∫¢I TRUY·ªÜN ‚ú®‚ú®‚ú® ===")

        # Nh·∫≠p URL truy·ªán
        url = input("üìù Nh·∫≠p URL truy·ªán: ")

        # T·∫£i truy·ªán
        print("üîó URL truy·ªán: " + url)
        download_novel(url)
    except Exception as e:
        print("‚ùå L·ªói kh√¥ng x·ª≠ l√Ω ƒë∆∞·ª£c trong ch∆∞∆°ng tr√¨nh ch√≠nh: " + str(e))
        traceback.print_exc()

# Ch·∫°y ch∆∞∆°ng tr√¨nh
if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print("‚ùå L·ªói nghi√™m tr·ªçng: " + str(e))
        traceback.print_exc()
        print("Ch∆∞∆°ng tr√¨nh ƒë√£ k·∫øt th√∫c kh√¥ng nh∆∞ mong ƒë·ª£i.")